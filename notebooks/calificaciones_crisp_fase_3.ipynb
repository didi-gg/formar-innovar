{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre procesamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Variables Objetivo y Características \n",
    "- **Variables objetivo (target)**: predecir el rendimiento por grado por materia,  usando cada una de las calificaciones (Cognitiva, Procedimental, Actitudinal, Axiologica) como variable objetivo.\n",
    "- **Características (features)**: Las demás columnas se utilizarán como características para predecir la variable objetivo.\n",
    "\n",
    "##### 2. Tipos de Variables: \n",
    "- **Variables categóricas**: Sede, Estudiante, Grado, Grupo, Periodo, Año, Asignatura.\n",
    "- **Variables numéricas**: Intensidad Horaria, Cognitiva, Procedimental, Actitudinal, Axiologica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupar por Grado y Asignatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones_to_model_fusa = pd.read_csv(\"calificaciones_to_model_fusa.csv\")\n",
    "calificaciones_to_model_girardot = pd.read_csv(\"calificaciones_to_model_girardot.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas numéricas\n",
    "numerical_columns = ['Intensidad Horaria', 'Cognitiva', 'Procedimental', 'Actitudinal', 'Axiologica','Calificacion_Ponderada']\n",
    "\n",
    "calificaciones_grouped_fusa = calificaciones_to_model_fusa.groupby(['Grado','Asignatura','Periodo','Año'])[numerical_columns].mean().reset_index()\n",
    "calificaciones_grouped_girardot = calificaciones_to_model_girardot.groupby(['Grado', 'Asignatura','Periodo','Año'])[numerical_columns].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 756 entries, 0 to 755\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Grado                   756 non-null    int64  \n",
      " 1   Asignatura              756 non-null    object \n",
      " 2   Periodo                 756 non-null    object \n",
      " 3   Año                     756 non-null    int64  \n",
      " 4   Intensidad Horaria      756 non-null    float64\n",
      " 5   Cognitiva               756 non-null    float64\n",
      " 6   Procedimental           756 non-null    float64\n",
      " 7   Actitudinal             756 non-null    float64\n",
      " 8   Axiologica              756 non-null    float64\n",
      " 9   Calificacion_Ponderada  756 non-null    float64\n",
      "dtypes: float64(6), int64(2), object(2)\n",
      "memory usage: 59.2+ KB\n"
     ]
    }
   ],
   "source": [
    "calificaciones_grouped_fusa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 528 entries, 0 to 527\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Grado                   528 non-null    int64  \n",
      " 1   Asignatura              528 non-null    object \n",
      " 2   Periodo                 528 non-null    object \n",
      " 3   Año                     528 non-null    int64  \n",
      " 4   Intensidad Horaria      528 non-null    float64\n",
      " 5   Cognitiva               528 non-null    float64\n",
      " 6   Procedimental           528 non-null    float64\n",
      " 7   Actitudinal             528 non-null    float64\n",
      " 8   Axiologica              528 non-null    float64\n",
      " 9   Calificacion_Ponderada  528 non-null    float64\n",
      "dtypes: float64(6), int64(2), object(2)\n",
      "memory usage: 41.4+ KB\n"
     ]
    }
   ],
   "source": [
    "calificaciones_grouped_girardot.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables características (features) y objetivo (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fusa = calificaciones_grouped_fusa[['Grado', 'Asignatura', 'Intensidad Horaria','Periodo','Año']]\n",
    "y_fusa = calificaciones_grouped_fusa[['Calificacion_Ponderada']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_girardot = calificaciones_grouped_girardot[['Grado', 'Asignatura', 'Intensidad Horaria','Periodo','Año']]\n",
    "y_girardot = calificaciones_grouped_girardot[['Calificacion_Ponderada']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado con Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Funcion modelado Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_random_forest_r(X, y):\n",
    "    # Definir el preprocesador\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), ['Intensidad Horaria']),\n",
    "            ('cat', OneHotEncoder(), ['Grado', 'Asignatura', 'Periodo', 'Año'])\n",
    "        ])\n",
    "    \n",
    "    # Crear el pipeline para el modelo Random Forest\n",
    "    model_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', RandomForestRegressor())])\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entrenar el modelo Random Forest\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    score = model_rf.score(X_test, y_test)\n",
    "    print(f'R^2 Score: {score:.2f}')\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    y_pred = model_rf.predict(X_test)\n",
    "    # Obtener otras métricas si es necesario\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'Mean Absolute Error: {mae:.2f}')\n",
    "    return model_rf, score, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_evaluate_svr(X, y):\n",
    "    \n",
    "    # Definir el preprocesador\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), ['Intensidad Horaria']),\n",
    "            ('cat', OneHotEncoder(), ['Grado', 'Asignatura','Periodo','Año'])\n",
    "        ])\n",
    "    \n",
    "    # Crear el pipeline para el modelo SVM\n",
    "    model_svr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', SVR())])\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entrenar el modelo SVM\n",
    "    model_svr.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    score = model_svr.score(X_test, y_test)\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    y_pred = model_svr.predict(X_test)\n",
    "    \n",
    "    return model_svr, score, y_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Funcion graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_test, y_pred, title_prefix):\n",
    "    # Convertir a numpy arrays si es necesario\n",
    "    y_test = y_test.to_numpy() if hasattr(y_test, 'to_numpy') else y_test\n",
    "    y_pred = y_pred.to_numpy() if hasattr(y_pred, 'to_numpy') else y_pred\n",
    "    \n",
    "    # Gráfico de Predicciones vs. Valores Reales\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.3, edgecolor='k')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "    plt.title(f'{title_prefix} - Predicciones vs. Valores Reales')\n",
    "    plt.xlabel('Valores Reales')\n",
    "    plt.ylabel('Predicciones')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Gráfico de Errores\n",
    "    errors = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.title(f'{title_prefix} - Distribución de Errores de Predicción')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar y evaluar modelo RandomForestRegression para Fusagasugá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.53\n",
      "Mean Squared Error: 10.45\n",
      "Mean Absolute Error: 2.37\n",
      "Fusagasugá - RandomForestRegression R^2 Score: 0.53\n"
     ]
    }
   ],
   "source": [
    "model_f, score_f, y_test_f, y_pred_f = train_evaluate_random_forest_r(X_fusa, y_fusa)\n",
    "print(f'Fusagasugá - RandomForestRegression R^2 Score: {score_f:.2f}')\n",
    "\n",
    "#plot_results(y_test_f, y_pred_f, 'Fusagasugá')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar y evaluar modelo RandomForestRegression para Girardot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.39\n",
      "Mean Squared Error: 15.63\n",
      "Mean Absolute Error: 2.85\n",
      "Girardot - RandomForestRegression R^2 Score: 0.39\n"
     ]
    }
   ],
   "source": [
    "model_g, score_g, y_test_g, y_pred_g = train_evaluate_random_forest_r(X_girardot, y_girardot)\n",
    "print(f'Girardot - RandomForestRegression R^2 Score: {score_g:.2f}')\n",
    "#plot_results(y_test_g, y_pred_g, 'Girardot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar y evaluar modelo SVR para Fusa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusagasugá - SVR R^2 Score: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_f2, score_f2, y_test_f2, y_pred_f2 = train_evaluate_svr(X_fusa, y_fusa)\n",
    "print(f'Fusagasugá - SVR R^2 Score: {score_f:.2f}')\n",
    "#plot_results(y_test_f2, y_pred_f2, 'Fusagasugá')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar y evaluar modelo SVR para Girardot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girardot - SVR R^2 Score: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_g2, score_g2, y_test_g2, y_pred_g2 = train_evaluate_svr(X_girardot, y_girardot)\n",
    "print(f'Girardot - SVR R^2 Score: {score_g:.2f}')\n",
    "#plot_results(y_test_g2, y_pred_g2, 'Girardot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cambiar valor de notas a categoricos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, column_name, bins, labels):\n",
    "    \n",
    "    df[column_name + '_Categorico'] = pd.cut(df[column_name], bins=bins, labels=labels, include_lowest=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos = [0, 60, 75, 90, 100]  # Definir los intervalos para las categorías\n",
    "clases = ['Muy Bajo', 'Bajo', 'Medio', 'Alto']  # Etiquetas para las categorías\n",
    "\n",
    "# Supongamos que 'Calificacion_Ponderada' es la columna a convertir\n",
    "calificaciones_grouped_fusa = convert_to_categorical(calificaciones_grouped_fusa, 'Calificacion_Ponderada', intervalos, clases)\n",
    "calificaciones_grouped_girardot = convert_to_categorical(calificaciones_grouped_girardot, 'Calificacion_Ponderada', intervalos, clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grado</th>\n",
       "      <th>Asignatura</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Año</th>\n",
       "      <th>Intensidad Horaria</th>\n",
       "      <th>Cognitiva</th>\n",
       "      <th>Procedimental</th>\n",
       "      <th>Actitudinal</th>\n",
       "      <th>Axiologica</th>\n",
       "      <th>Calificacion_Ponderada</th>\n",
       "      <th>Calificacion_Ponderada_Categorico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>I</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.636364</td>\n",
       "      <td>87.181818</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>92.545455</td>\n",
       "      <td>88.363636</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>I</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.200000</td>\n",
       "      <td>89.533333</td>\n",
       "      <td>90.266667</td>\n",
       "      <td>93.466667</td>\n",
       "      <td>89.540000</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>II</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>88.444444</td>\n",
       "      <td>93.166667</td>\n",
       "      <td>93.722222</td>\n",
       "      <td>89.872222</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>II</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.933333</td>\n",
       "      <td>92.600000</td>\n",
       "      <td>90.733333</td>\n",
       "      <td>94.200000</td>\n",
       "      <td>92.120000</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>III</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.368421</td>\n",
       "      <td>93.421053</td>\n",
       "      <td>93.526316</td>\n",
       "      <td>92.421053</td>\n",
       "      <td>93.321053</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grado                       Asignatura Periodo   Año  Intensidad Horaria  \\\n",
       "0      1  Aprendizaje Basado en Proyectos       I  2023                 4.0   \n",
       "1      1  Aprendizaje Basado en Proyectos       I  2024                 2.0   \n",
       "2      1  Aprendizaje Basado en Proyectos      II  2023                 4.0   \n",
       "3      1  Aprendizaje Basado en Proyectos      II  2024                 2.0   \n",
       "4      1  Aprendizaje Basado en Proyectos     III  2023                 4.0   \n",
       "\n",
       "   Cognitiva  Procedimental  Actitudinal  Axiologica  Calificacion_Ponderada  \\\n",
       "0  87.636364      87.181818    89.500000   92.545455               88.363636   \n",
       "1  88.200000      89.533333    90.266667   93.466667               89.540000   \n",
       "2  88.333333      88.444444    93.166667   93.722222               89.872222   \n",
       "3  91.933333      92.600000    90.733333   94.200000               92.120000   \n",
       "4  93.368421      93.421053    93.526316   92.421053               93.321053   \n",
       "\n",
       "  Calificacion_Ponderada_Categorico  \n",
       "0                             Medio  \n",
       "1                             Medio  \n",
       "2                             Medio  \n",
       "3                              Alto  \n",
       "4                              Alto  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calificaciones_grouped_fusa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grado</th>\n",
       "      <th>Asignatura</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Año</th>\n",
       "      <th>Intensidad Horaria</th>\n",
       "      <th>Cognitiva</th>\n",
       "      <th>Procedimental</th>\n",
       "      <th>Actitudinal</th>\n",
       "      <th>Axiologica</th>\n",
       "      <th>Calificacion_Ponderada</th>\n",
       "      <th>Calificacion_Ponderada_Categorico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>I</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82.300000</td>\n",
       "      <td>83.400000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>85.800000</td>\n",
       "      <td>82.640000</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>I</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89.687500</td>\n",
       "      <td>90.250000</td>\n",
       "      <td>86.125000</td>\n",
       "      <td>85.875000</td>\n",
       "      <td>88.762500</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>II</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>85.727273</td>\n",
       "      <td>85.818182</td>\n",
       "      <td>90.090909</td>\n",
       "      <td>88.818182</td>\n",
       "      <td>86.936364</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>II</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.277778</td>\n",
       "      <td>92.166667</td>\n",
       "      <td>88.944444</td>\n",
       "      <td>91.444444</td>\n",
       "      <td>91.494444</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprendizaje Basado en Proyectos</td>\n",
       "      <td>III</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.363636</td>\n",
       "      <td>91.272727</td>\n",
       "      <td>93.181818</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>91.563636</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grado                       Asignatura Periodo   Año  Intensidad Horaria  \\\n",
       "0      1  Aprendizaje Basado en Proyectos       I  2023                 4.0   \n",
       "1      1  Aprendizaje Basado en Proyectos       I  2024                 2.0   \n",
       "2      1  Aprendizaje Basado en Proyectos      II  2023                 4.0   \n",
       "3      1  Aprendizaje Basado en Proyectos      II  2024                 2.0   \n",
       "4      1  Aprendizaje Basado en Proyectos     III  2023                 4.0   \n",
       "\n",
       "   Cognitiva  Procedimental  Actitudinal  Axiologica  Calificacion_Ponderada  \\\n",
       "0  82.300000      83.400000    80.600000   85.800000               82.640000   \n",
       "1  89.687500      90.250000    86.125000   85.875000               88.762500   \n",
       "2  85.727273      85.818182    90.090909   88.818182               86.936364   \n",
       "3  92.277778      92.166667    88.944444   91.444444               91.494444   \n",
       "4  90.363636      91.272727    93.181818   94.000000               91.563636   \n",
       "\n",
       "  Calificacion_Ponderada_Categorico  \n",
       "0                             Medio  \n",
       "1                             Medio  \n",
       "2                             Medio  \n",
       "3                              Alto  \n",
       "4                              Alto  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calificaciones_grouped_girardot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fusa_c = calificaciones_grouped_fusa[['Grado', 'Asignatura', 'Intensidad Horaria','Periodo','Año']]\n",
    "y_fusa_c = calificaciones_grouped_fusa[['Calificacion_Ponderada_Categorico']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_girardot_c = calificaciones_grouped_girardot[['Grado', 'Asignatura', 'Intensidad Horaria','Periodo','Año']]\n",
    "y_girardot_c = calificaciones_grouped_girardot[['Calificacion_Ponderada_Categorico']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funciones de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def train_evaluate_random_forest(X, y):\n",
    "\n",
    "    # Definir el preprocesador\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), ['Intensidad Horaria']),\n",
    "            ('cat', OneHotEncoder(), ['Grado', 'Asignatura', 'Periodo', 'Año'])\n",
    "        ])\n",
    "    \n",
    "    # Crear el pipeline para el modelo Random Forest\n",
    "    model_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', RandomForestClassifier())])\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entrenar el modelo Random Forest\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Realizar predicciones\n",
    "    y_pred = model_rf.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Random Forest - Accuracy: {accuracy:.2f}')\n",
    "    print(f'Random Forest - Precision: {precision:.2f}')\n",
    "    print(f'Random Forest - Recall: {recall:.2f}')\n",
    "    print(f'Random Forest - F1 Score: {f1:.2f}')\n",
    "    \n",
    "    return model_rf, accuracy, precision, recall, f1, y_test, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_evaluate_svc(X, y):\n",
    "\n",
    "    # Definir el preprocesador\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), ['Intensidad Horaria']),\n",
    "            ('cat', OneHotEncoder(), ['Grado', 'Asignatura', 'Periodo', 'Año'])\n",
    "        ])\n",
    "    \n",
    "    # Crear el pipeline para el modelo Random Forest\n",
    "    model_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', SVC())])\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entrenar el modelo Random Forest\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Realizar predicciones\n",
    "    y_pred = model_rf.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f'Random Forest - Accuracy: {accuracy:.2f}')\n",
    "    print(f'Random Forest - Precision: {precision:.2f}')\n",
    "    print(f'Random Forest - Recall: {recall:.2f}')\n",
    "    print(f'Random Forest - F1 Score: {f1:.2f}')\n",
    "    \n",
    "    return model_rf, accuracy, precision, recall, f1, y_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ejecucion modelos de clasificacion para Fusa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.86\n",
      "Random Forest - Precision: 0.85\n",
      "Random Forest - Recall: 0.86\n",
      "Random Forest - F1 Score: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model_f3, accuracy_f3, precision_f3, recall_f3, f1_f3, y_test_f3, y_pred_f3 = train_evaluate_random_forest(X_fusa_c, y_fusa_c)\n",
    "#plot_results(y_test_f3, y_pred_f3, 'Fusagasugá')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.83\n",
      "Random Forest - Precision: 0.81\n",
      "Random Forest - Recall: 0.83\n",
      "Random Forest - F1 Score: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model_f4, accuracy_f4, precision_f4, recall_f4, f1_f4, y_test_f4, y_pred_f4 = train_evaluate_svc(X_fusa_c, y_fusa_c)\n",
    "#plot_results(y_test_f4, y_pred_f4, 'Fusagasugá')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ejecucion modelos de clasificacion para Girardot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.80\n",
      "Random Forest - Precision: 0.78\n",
      "Random Forest - Recall: 0.80\n",
      "Random Forest - F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "model_g3, accuracy_g3, precision_g3, recall_g3, f1_g3, y_test_g3, y_pred_g3 = train_evaluate_random_forest(X_girardot_c, y_girardot_c)\n",
    "#plot_results(y_test_g3, y_pred_g3, 'Girardot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.80\n",
      "Random Forest - Precision: 0.79\n",
      "Random Forest - Recall: 0.80\n",
      "Random Forest - F1 Score: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Cathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model_g4, accuracy_g4, precision_g4, recall_g4, f1_g4, y_test_g4, y_pred_g4 = train_evaluate_svc(X_girardot_c, y_girardot_c)\n",
    "#plot_results(y_test_g3, y_pred_g3, 'Girardot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
